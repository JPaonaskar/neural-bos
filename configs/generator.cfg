[net]
# Training
channels = 3

# Hyperparameters
learning_rate = 2e-4
beta1 = 0.5
l1_lambda = 100

# init parameter distribution
init_weight_mean = 0.0
init_weight_stdev = 0.02

[convolutional]
feature = 64

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

# Encoder
[convolutional]
batch_normalize = 1
feature = 128

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

[convolutional]
batch_normalize = 1
feature = 256

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

[convolutional]
batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

[convolutional]
batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

[convolutional]
batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

[convolutional]
batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = leaky
negitive_slope = 0.2

# Bottleneck
[convolutional]
feature = 512

size = 4
stride = 2
pad = 1
padding_mode = reflect

activation = linear

# Decoder
[convolutional]
transpose = 1
batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1

activation = relu
dropout = 0.5

[convolutional]
transpose = 1
from = -3

batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1

activation = relu
dropout = 0.5

[convolutional]
transpose = 1
from = -5

batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1

activation = relu
dropout = 0.5

[convolutional]
transpose = 1
from = -7

batch_normalize = 1
feature = 512

size = 4
stride = 2
pad = 1

activation = relu

[convolutional]
transpose = 1
from = -9

batch_normalize = 1
feature = 256

size = 4
stride = 2
pad = 1

activation = relu

[convolutional]
transpose = 1
from = -11

batch_normalize = 1
feature = 128

size = 4
stride = 2
pad = 1

activation = relu

[convolutional]
transpose = 1
from = -13

batch_normalize = 1
feature = 64

size = 4
stride = 2
pad = 1

activation = relu

# Output head
[convolutional]
transpose = 1
from = -15

feature = 3

size = 4
stride = 2
pad = 1

activation = tanh